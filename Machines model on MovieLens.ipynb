{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-04-06 12:52:53--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4924029 (4.7M) [application/zip]\n",
      "Saving to: 'ml-100k.zip'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  110K 43s\n",
      "    50K .......... .......... .......... .......... ..........  2%  217K 32s\n",
      "   100K .......... .......... .......... .......... ..........  3% 1.55M 22s\n",
      "   150K .......... .......... .......... .......... ..........  4%  214K 22s\n",
      "   200K .......... .......... .......... .......... ..........  5% 3.05M 18s\n",
      "   250K .......... .......... .......... .......... ..........  6%  247K 18s\n",
      "   300K .......... .......... .......... .......... ..........  7% 2.52M 15s\n",
      "   350K .......... .......... .......... .......... ..........  8% 1.67M 13s\n",
      "   400K .......... .......... .......... .......... ..........  9% 3.64M 12s\n",
      "   450K .......... .......... .......... .......... .......... 10% 2.74M 11s\n",
      "   500K .......... .......... .......... .......... .......... 11% 2.64M 10s\n",
      "   550K .......... .......... .......... .......... .......... 12%  329K 10s\n",
      "   600K .......... .......... .......... .......... .......... 13% 1.13M 9s\n",
      "   650K .......... .......... .......... .......... .......... 14% 4.53M 9s\n",
      "   700K .......... .......... .......... .......... .......... 15%  101K 11s\n",
      "   750K .......... .......... .......... .......... .......... 16% 35.6M 10s\n",
      "   800K .......... .......... .......... .......... .......... 17%  108K 11s\n",
      "   850K .......... .......... .......... .......... .......... 18% 6.62M 11s\n",
      "   900K .......... .......... .......... .......... .......... 19% 90.9K 12s\n",
      "   950K .......... .......... .......... .......... .......... 20% 5.73M 11s\n",
      "  1000K .......... .......... .......... .......... .......... 21% 31.9K 16s\n",
      "  1050K .......... .......... .......... .......... .......... 22% 29.0M 15s\n",
      "  1100K .......... .......... .......... .......... .......... 23% 58.4M 15s\n",
      "  1150K .......... .......... .......... .......... .......... 24% 50.1M 14s\n",
      "  1200K .......... .......... .......... .......... .......... 25% 58.8M 13s\n",
      "  1250K .......... .......... .......... .......... .......... 27% 55.3M 12s\n",
      "  1300K .......... .......... .......... .......... .......... 28% 66.3M 12s\n",
      "  1350K .......... .......... .......... .......... .......... 29% 40.1M 11s\n",
      "  1400K .......... .......... .......... .......... .......... 30% 56.4M 11s\n",
      "  1450K .......... .......... .......... .......... .......... 31%  191K 11s\n",
      "  1500K .......... .......... .......... .......... .......... 32% 4.14M 10s\n",
      "  1550K .......... .......... .......... .......... .......... 33% 2.84M 10s\n",
      "  1600K .......... .......... .......... .......... .......... 34% 9.71M 9s\n",
      "  1650K .......... .......... .......... .......... .......... 35% 75.7M 9s\n",
      "  1700K .......... .......... .......... .......... .......... 36% 62.6M 9s\n",
      "  1750K .......... .......... .......... .......... .......... 37% 57.4M 8s\n",
      "  1800K .......... .......... .......... .......... .......... 38% 84.3M 8s\n",
      "  1850K .......... .......... .......... .......... .......... 39% 2.02M 7s\n",
      "  1900K .......... .......... .......... .......... .......... 40% 1.57M 7s\n",
      "  1950K .......... .......... .......... .......... .......... 41% 9.51M 7s\n",
      "  2000K .......... .......... .......... .......... .......... 42% 1.88M 7s\n",
      "  2050K .......... .......... .......... .......... .......... 43% 1.19M 6s\n",
      "  2100K .......... .......... .......... .......... .......... 44% 63.7M 6s\n",
      "  2150K .......... .......... .......... .......... .......... 45%  971K 6s\n",
      "  2200K .......... .......... .......... .......... .......... 46% 2.74M 6s\n",
      "  2250K .......... .......... .......... .......... .......... 47% 40.0K 7s\n",
      "  2300K .......... .......... .......... .......... .......... 48% 24.3M 7s\n",
      "  2350K .......... .......... .......... .......... .......... 49%  197K 7s\n",
      "  2400K .......... .......... .......... .......... .......... 50%  223K 7s\n",
      "  2450K .......... .......... .......... .......... .......... 51% 5.92M 6s\n",
      "  2500K .......... .......... .......... .......... .......... 53% 47.1M 6s\n",
      "  2550K .......... .......... .......... .......... .......... 54% 68.0M 6s\n",
      "  2600K .......... .......... .......... .......... .......... 55% 42.8M 6s\n",
      "  2650K .......... .......... .......... .......... .......... 56% 45.2M 5s\n",
      "  2700K .......... .......... .......... .......... .......... 57% 29.4M 5s\n",
      "  2750K .......... .......... .......... .......... .......... 58% 4.57M 5s\n",
      "  2800K .......... .......... .......... .......... .......... 59% 8.58M 5s\n",
      "  2850K .......... .......... .......... .......... .......... 60% 26.2M 4s\n",
      "  2900K .......... .......... .......... .......... .......... 61% 14.9M 4s\n",
      "  2950K .......... .......... .......... .......... .......... 62% 53.0M 4s\n",
      "  3000K .......... .......... .......... .......... .......... 63% 50.8M 4s\n",
      "  3050K .......... .......... .......... .......... .......... 64% 6.09M 4s\n",
      "  3100K .......... .......... .......... .......... .......... 65% 48.2M 4s\n",
      "  3150K .......... .......... .......... .......... .......... 66% 46.8M 3s\n",
      "  3200K .......... .......... .......... .......... .......... 67% 52.7M 3s\n",
      "  3250K .......... .......... .......... .......... .......... 68% 38.4M 3s\n",
      "  3300K .......... .......... .......... .......... .......... 69% 67.0M 3s\n",
      "  3350K .......... .......... .......... .......... .......... 70% 5.11M 3s\n",
      "  3400K .......... .......... .......... .......... .......... 71% 3.02M 3s\n",
      "  3450K .......... .......... .......... .......... .......... 72%  316K 3s\n",
      "  3500K .......... .......... .......... .......... .......... 73%  946K 3s\n",
      "  3550K .......... .......... .......... .......... .......... 74% 4.64M 2s\n",
      "  3600K .......... .......... .......... .......... .......... 75% 2.30M 2s\n",
      "  3650K .......... .......... .......... .......... .......... 76% 3.83M 2s\n",
      "  3700K .......... .......... .......... .......... .......... 77% 62.9K 2s\n",
      "  3750K .......... .......... .......... .......... .......... 79%  157K 2s\n",
      "  3800K .......... .......... .......... .......... .......... 80% 15.7M 2s\n",
      "  3850K .......... .......... .......... .......... .......... 81% 55.2M 2s\n",
      "  3900K .......... .......... .......... .......... .......... 82% 61.9M 2s\n",
      "  3950K .......... .......... .......... .......... .......... 83% 64.8M 2s\n",
      "  4000K .......... .......... .......... .......... .......... 84% 46.5M 2s\n",
      "  4050K .......... .......... .......... .......... .......... 85% 21.6M 1s\n",
      "  4100K .......... .......... .......... .......... .......... 86% 59.3M 1s\n",
      "  4150K .......... .......... .......... .......... .......... 87%  132K 1s\n",
      "  4200K .......... .......... .......... .......... .......... 88%  444K 1s\n",
      "  4250K .......... .......... .......... .......... .......... 89% 38.6M 1s\n",
      "  4300K .......... .......... .......... .......... .......... 90% 43.8M 1s\n",
      "  4350K .......... .......... .......... .......... .......... 91% 53.7M 1s\n",
      "  4400K .......... .......... .......... .......... .......... 92% 10.2M 1s\n",
      "  4450K .......... .......... .......... .......... .......... 93% 2.99M 1s\n",
      "  4500K .......... .......... .......... .......... .......... 94%  189K 1s\n",
      "  4550K .......... .......... .......... .......... .......... 95% 80.9M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 96% 37.0M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 97% 49.6M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 98% 44.8M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 99% 73.2M 0s\n",
      "  4800K ........                                              100% 49.7M=9.0s\n",
      "\n",
      "2021-04-06 12:53:04 (532 KB/s) - 'ml-100k.zip' saved [4924029/4924029]\n",
      "\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>5</th>\n",
       "      <th>874965758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>887431973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  1.1  5  874965758\n",
       "0  1    2  3  876893171\n",
       "1  1    3  4  878542960\n",
       "2  1    4  3  876893119\n",
       "3  1    5  3  889751712\n",
       "4  1    6  5  887431973"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('D:/ml-100k/ua.base',sep=\"\t\")\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>5</th>\n",
       "      <th>874965758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9836</th>\n",
       "      <td>98</td>\n",
       "      <td>435</td>\n",
       "      <td>5</td>\n",
       "      <td>880498967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35449</th>\n",
       "      <td>354</td>\n",
       "      <td>922</td>\n",
       "      <td>4</td>\n",
       "      <td>891216825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62713</th>\n",
       "      <td>629</td>\n",
       "      <td>729</td>\n",
       "      <td>4</td>\n",
       "      <td>880117852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36299</th>\n",
       "      <td>368</td>\n",
       "      <td>777</td>\n",
       "      <td>2</td>\n",
       "      <td>889783586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66840</th>\n",
       "      <td>664</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>876525044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1  1.1  5  874965758\n",
       "9836    98  435  5  880498967\n",
       "35449  354  922  4  891216825\n",
       "62713  629  729  4  880117852\n",
       "36299  368  777  2  889783586\n",
       "66840  664  318  5  876525044"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 943\n",
    "num_movies = 1682\n",
    "num_features = num_users+num_movies\n",
    "num_ratings_train = 90570\n",
    "num_ratings_test = 9430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "def loadDataset(filename, lines, columns):\n",
    "    X = lil_matrix((lines, columns)).astype('float32')\n",
    "    Y = []\n",
    "    line=0\n",
    "    with open(filename,'r') as f:\n",
    "        samples=csv.reader(f,delimiter='\\t')\n",
    "        for userId,movieId,rating,timestamp in samples:\n",
    "            X[line,int(userId)-1] = 1\n",
    "            X[line,int(num_users)+int(movieId)-1] = 1\n",
    "            Y.append(int(rating))\n",
    "            line=line+1\n",
    "    Y=np.array(Y).astype('float32')\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = loadDataset('D:/ml-100k/ua.base',num_ratings_train,num_features)\n",
    "X_test, Y_test = loadDataset('D:/ml-100k/ua.test',num_ratings_test,num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 2625)\n",
      "(90570,)\n",
      "(9430, 2625)\n",
      "(9430,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, boto3\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'fm-movielens'\n",
    "train_key = 'train.protobuf'\n",
    "train_prefix = '{}/{}'.format(prefix, 'train')\n",
    "test_key = 'test.protobuf'\n",
    "test_prefix = '{}/{}'.format(prefix, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prefix = 's3://{}/{}/output'.format(bucket,prefix)\n",
    "train_data = writeDatasetToProtobuf(X_train, Y_train,bucket, train_prefix, train_key)\n",
    "test_data = writeDatasetToProtobuf(X_test, Y_test,bucket, test_prefix, test_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::501851762093:role/service-role/AmazonSageMaker-ExecutionRole-20210211T005553'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "def resolve_sm_role():\n",
    "    client = boto3.client('iam', region_name=region)\n",
    "    response_roles = client.list_roles(PathPrefix='/',\n",
    "                                       # Marker='string'\n",
    "                                       MaxItems=999) \n",
    "    for role in response_roles['Roles']:\n",
    "        if role['RoleName'].startswith('AmazonSageMaker-ExecutionRole-'):\n",
    "               # print('Resolved SageMaker IAM Role to: ' + str(role))\n",
    "                return role['Arn']\n",
    "    raise Exception('Could not resolve what should be the SageMaker role to be used')\n",
    "                        #resolve_sm_role()\n",
    "                        #role = get_execution_role()\n",
    "role = resolve_sm_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "region=boto3.Session().region_name\n",
    "container=image_uris.retrieve('factorization-machines',\n",
    "region)\n",
    "fm=sagemaker.estimator.Estimator(\n",
    "container,\n",
    "role=role,\n",
    "instance_count=1,\n",
    "instance_type='ml.m4.xlarge',\n",
    "output_path=output_prefix)\n",
    "fm.set_hyperparameters(\n",
    "feature_dim=num_features,\n",
    "predictor_type='regressor',\n",
    "num_factors=64,\n",
    "epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-06 08:11:54 Starting - Starting the training job...\n",
      "2021-04-06 08:12:18 Starting - Launching requested ML instancesProfilerReport-1617696715: InProgress\n",
      "......\n",
      "2021-04-06 08:13:18 Starting - Preparing the instances for training......\n",
      "2021-04-06 08:14:39 Downloading - Downloading input data...\n",
      "2021-04-06 08:14:59 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:87: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:120: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '2625', 'predictor_type': 'regressor', 'num_factors': '64', 'epochs': '10'}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] Final configuration: {'epochs': '10', 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '2625', 'predictor_type': 'regressor', 'num_factors': '64'}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 WARNING 140519436588864] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:26.670] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:26.675] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 9, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] nvidia-smi took: 0.025267601013183594 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696926.6655564, \"EndTime\": 1617696926.712839, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 39.50190544128418, \"count\": 1, \"min\": 39.50190544128418, \"max\": 39.50190544128418}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696926.7129989, \"EndTime\": 1617696926.7130485, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[08:15:26] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204326.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[08:15:26] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204326.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.7992418034721087\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=14.43423828125\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:26 INFO 140519436588864] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.592279052734375\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:27.309] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 570, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.7620200724636264\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=0, train mse <loss>=3.1047147357647233\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.391475620814732\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696926.7129333, \"EndTime\": 1617696927.3105657, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"update.time\": {\"sum\": 597.1765518188477, \"count\": 1, \"min\": 597.1765518188477, \"max\": 597.1765518188477}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696926.7133527, \"EndTime\": 1617696927.310834, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 91570.0, \"count\": 1, \"min\": 91570, \"max\": 91570}, \"Total Batches Seen\": {\"sum\": 92.0, \"count\": 1, \"min\": 92, \"max\": 92}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=151552.72227350957 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.2368668973174468\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.5298397216796875\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=1.057596435546875\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:27.906] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 593, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.141202065822414\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.3023421550373455\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.9548139205764938\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696927.3106537, \"EndTime\": 1617696927.9075098, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 595.9069728851318, \"count\": 1, \"min\": 595.9069728851318, \"max\": 595.9069728851318}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696927.3115652, \"EndTime\": 1617696927.9078343, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 182140.0, \"count\": 1, \"min\": 182140, \"max\": 182140}, \"Total Batches Seen\": {\"sum\": 183.0, \"count\": 1, \"min\": 183, \"max\": 183}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=151855.02996501417 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.22731217137924\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.506295166015625\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:27 INFO 140519436588864] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=1.0498385009765625\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:28.640] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 730, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:28 INFO 140519436588864] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.1323676718169053\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:28 INFO 140519436588864] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.2822565441760387\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:28 INFO 140519436588864] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.9460046333061469\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696927.9076095, \"EndTime\": 1617696928.6424913, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 733.7334156036377, \"count\": 1, \"min\": 733.7334156036377, \"max\": 733.7334156036377}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:28 INFO 140519436588864] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696927.908643, \"EndTime\": 1617696928.6430025, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 272710.0, \"count\": 1, \"min\": 272710, \"max\": 272710}, \"Total Batches Seen\": {\"sum\": 274.0, \"count\": 1, \"min\": 274, \"max\": 274}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:28 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=123302.66113444335 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:28 INFO 140519436588864] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.215051730589201\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:28 INFO 140519436588864] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.4763507080078124\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:28 INFO 140519436588864] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=1.0379765625\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:29.362] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 714, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:29 INFO 140519436588864] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.1234819583934363\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:29 INFO 140519436588864] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.262211710835551\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:29 INFO 140519436588864] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.936996818793999\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696928.6426306, \"EndTime\": 1617696929.3639085, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 720.0732231140137, \"count\": 1, \"min\": 720.0732231140137, \"max\": 720.0732231140137}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:29 INFO 140519436588864] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696928.6437962, \"EndTime\": 1617696929.364261, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 363280.0, \"count\": 1, \"min\": 363280, \"max\": 363280}, \"Total Batches Seen\": {\"sum\": 365.0, \"count\": 1, \"min\": 365, \"max\": 365}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:29 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=125681.54097953877 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:29 INFO 140519436588864] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.2030638681709453\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:29 INFO 140519436588864] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.4473626708984375\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:29 INFO 140519436588864] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=1.0260322265625\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:30.021] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 654, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.1149099702166483\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.2430242416884874\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.9280047533643114\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696929.3640063, \"EndTime\": 1617696930.0216684, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 656.6548347473145, \"count\": 1, \"min\": 656.6548347473145, \"max\": 656.6548347473145}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696929.3649828, \"EndTime\": 1617696930.0219052, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 453850.0, \"count\": 1, \"min\": 453850, \"max\": 453850}, \"Total Batches Seen\": {\"sum\": 456.0, \"count\": 1, \"min\": 456, \"max\": 456}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=137843.6131549355 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.1917576838238237\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.420286376953125\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=1.0144755249023438\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:30.545] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 521, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.1068240394383524\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.2250594542786315\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.9192152146559495\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696930.0217488, \"EndTime\": 1617696930.5467033, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 524.0583419799805, \"count\": 1, \"min\": 524.0583419799805, \"max\": 524.0583419799805}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696930.0226068, \"EndTime\": 1617696930.5469952, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 544420.0, \"count\": 1, \"min\": 544420, \"max\": 544420}, \"Total Batches Seen\": {\"sum\": 547.0, \"count\": 1, \"min\": 547, \"max\": 547}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=172665.51244249643 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.1812418361159687\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.395332275390625\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:30 INFO 140519436588864] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=1.0034603271484375\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:31.130] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 580, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.0992773746785123\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.2084107464800824\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.9107236214103279\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696930.5468006, \"EndTime\": 1617696931.1310308, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 583.186149597168, \"count\": 1, \"min\": 583.186149597168, \"max\": 583.186149597168}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696930.5478055, \"EndTime\": 1617696931.1313078, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 634990.0, \"count\": 1, \"min\": 634990, \"max\": 634990}, \"Total Batches Seen\": {\"sum\": 638.0, \"count\": 1, \"min\": 638, \"max\": 638}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=155170.60080093722 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.1715178101472412\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.3724539794921875\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.9930307006835938\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:31.684] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 550, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.0922674413555689\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.1930481634454413\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.9025778982979911\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696931.1311247, \"EndTime\": 1617696931.6857953, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 553.77197265625, \"count\": 1, \"min\": 553.77197265625, \"max\": 553.77197265625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696931.131988, \"EndTime\": 1617696931.6861012, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 725560.0, \"count\": 1, \"min\": 725560, \"max\": 725560}, \"Total Batches Seen\": {\"sum\": 729.0, \"count\": 1, \"min\": 729, \"max\": 729}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=163405.09259653566 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.1625455195221122\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.3515120849609374\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:31 INFO 140519436588864] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.9831880493164062\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:32.213] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 524, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.0857648651714433\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.1788853424407624\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.894800058888865\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696931.6858993, \"EndTime\": 1617696932.2145991, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 527.6575088500977, \"count\": 1, \"min\": 527.6575088500977, \"max\": 527.6575088500977}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696931.6869066, \"EndTime\": 1617696932.2148354, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 816130.0, \"count\": 1, \"min\": 816130, \"max\": 816130}, \"Total Batches Seen\": {\"sum\": 820.0, \"count\": 1, \"min\": 820, \"max\": 820}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=171512.05835809393 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.1542686782723617\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.332336181640625\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.9739154663085937\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:32.744] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 526, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.0797283210037731\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.165813247177627\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.887407476739569\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, train rmse <loss>=1.0797283210037731\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, train mse <loss>=1.165813247177627\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, train absolute_loss <loss>=0.887407476739569\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696932.2146783, \"EndTime\": 1617696932.745485, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 529.8886299133301, \"count\": 1, \"min\": 529.8886299133301, \"max\": 529.8886299133301}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696932.2155607, \"EndTime\": 1617696932.7457798, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 906700.0, \"count\": 1, \"min\": 906700, \"max\": 906700}, \"Total Batches Seen\": {\"sum\": 911.0, \"count\": 1, \"min\": 911, \"max\": 911}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #throughput_metric: host=algo-1, train throughput=170768.1924365876 records/second\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 WARNING 140519436588864] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696932.7455814, \"EndTime\": 1617696932.7500257, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 3.856182098388672, \"count\": 1, \"min\": 3.856182098388672, \"max\": 3.856182098388672}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] Saved checkpoint to \"/tmp/tmp7nt73282/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:32.758] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 6088, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[2021-04-06 08:15:32.796] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 37, \"num_examples\": 10, \"num_bytes\": 603520}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696932.758759, \"EndTime\": 1617696932.7971466, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Total Batches Seen\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Max Records Seen Between Resets\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #test_score (algo-1) : ('rmse', 1.0605405328908513)\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #test_score (algo-1) : ('mse', 1.1247462219044109)\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #test_score (algo-1) : ('absolute_loss', 0.8816765988492511)\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, test rmse <loss>=1.0605405328908513\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, test mse <loss>=1.1247462219044109\u001b[0m\n",
      "\u001b[34m[04/06/2021 08:15:32 INFO 140519436588864] #quality_metric: host=algo-1, test absolute_loss <loss>=0.8816765988492511\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1617696932.750109, \"EndTime\": 1617696932.798146, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 23.648977279663086, \"count\": 1, \"min\": 23.648977279663086, \"max\": 23.648977279663086}, \"totaltime\": {\"sum\": 6163.742542266846, \"count\": 1, \"min\": 6163.742542266846, \"max\": 6163.742542266846}}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-04-06 08:15:42 Uploading - Uploading generated training model\n",
      "2021-04-06 08:15:42 Completed - Training job completed\n",
      "Training seconds: 76\n",
      "Billable seconds: 76\n"
     ]
    }
   ],
   "source": [
    "fm.fit({'train': train_data, 'test': test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "endpoint_name = 'fm-movielens-100k'\n",
    "class FMSerializer(JSONSerializer):\n",
    "    def serialize(self, data):\n",
    "        js = {'instances': []}\n",
    "        for row in data:\n",
    "            js['instances'].append({'features': row.tolist()})\n",
    "            return json.dumps(js)\n",
    "fm_predictor = fm.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    serializer=FMSerializer(),\n",
    "    deserializer= JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-04e776e25490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfm_predictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\sagemaker\\lib\\site-packages\\sagemaker\\predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, initial_args, target_model, target_variant)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \"\"\"\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mrequest_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\sagemaker\\lib\\site-packages\\sagemaker\\predictor.py\u001b[0m in \u001b[0;36m_create_request_args\u001b[1;34m(self, data, initial_args, target_model, target_variant)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TargetVariant\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserializer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Body\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-97816575ed82>\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'instances'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m fm_predictor = fm.deploy(\n\u001b[0;32m     11\u001b[0m     \u001b[0minitial_instance_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "result = fm_predictor.predict(X_test[:3].toarray())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker",
   "language": "python",
   "name": "sagemaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
